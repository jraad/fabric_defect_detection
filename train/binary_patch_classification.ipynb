{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "from utilities import AITEXPatched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "model_dir = os.path.join(root, \"models\")\n",
    "data_dir = os.path.join(root, \"data\")\n",
    "aitex_dir = os.path.join(data_dir, \"aitex\")\n",
    "\n",
    "# Load dataset with transforms and split\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224))\n",
    "])\n",
    "data = AITEXPatched(aitex_dir, transform=transform, greyscale=True)#, normal_only=True)\n",
    "num_samples = len(data)\n",
    "train_samples = int(num_samples * 0.95)\n",
    "val_samples = num_samples - train_samples\n",
    "train, val = random_split(data, [train_samples, val_samples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\compute\\envs\\fdd\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Apply weighting due to class imbalance\n",
    "class_counts = [data.has_defect.count(c) for c in range(2)]\n",
    "total_samples = sum(class_counts)\n",
    "class_weights = [total_samples / (2 * count) for count in class_counts]\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "sample_weights = [0] * len(train)\n",
    "for idx, (img, label) in enumerate(train):\n",
    "    sample_weights[idx] = class_weights[label]\n",
    "\n",
    "# Create data loaders with weighted sampling\n",
    "bs = 16\n",
    "train_sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "train_loader = DataLoader(train, batch_size=bs, sampler=train_sampler)#, num_workers=4)\n",
    "val_loader = DataLoader(val, batch_size=bs, shuffle=False)#, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model architecture\n",
    "# class BinaryClassifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BinaryClassifier, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#         )\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(32 * 56 * 56, 128),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(128, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 14 * 14, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BinaryClassifier().to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss(weight=class_weights[-1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    \"\"\"Calculate accuracy from og and pred labels.\"\"\"\n",
    "    predictions = (outputs >= 0.5).float()\n",
    "    correct = (predictions == labels).sum().item()\n",
    "    accuracy = correct / labels.size(0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|==========| 234/234 [00:07<00:00, 30.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Train Loss: 0.0015, Train Accuracy: 1.0000, Valid Loss: 8.3738, Valid Accuracy: 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|==========| 234/234 [00:07<00:00, 29.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/5, Train Loss: 0.0006, Train Accuracy: 1.0000, Valid Loss: 8.3703, Valid Accuracy: 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|==========| 234/234 [00:07<00:00, 30.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5, Train Loss: 0.0005, Train Accuracy: 1.0000, Valid Loss: 8.3802, Valid Accuracy: 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|==========| 234/234 [00:07<00:00, 30.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5, Train Loss: 0.0004, Train Accuracy: 1.0000, Valid Loss: 8.6600, Valid Accuracy: 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|==========| 234/234 [00:07<00:00, 30.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5, Train Loss: 0.0003, Train Accuracy: 1.0000, Valid Loss: 8.8433, Valid Accuracy: 0.9567\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    valid_loss = 0.0\n",
    "    valid_accuracy = 0.0\n",
    "    \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    with tqdm(train_loader, unit=\"batch\", ascii=' >=') as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            train_accuracy += calculate_accuracy(outputs, labels)\n",
    "    \n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            valid_loss += loss.item() * images.size(0)\n",
    "            valid_accuracy += calculate_accuracy(outputs, labels)\n",
    "    \n",
    "    # Calculate average losses and accuracy\n",
    "    train_loss = train_loss / len(train)\n",
    "    train_accuracy = train_accuracy / len(train_loader)\n",
    "    valid_loss = valid_loss / len(val)\n",
    "    valid_accuracy = valid_accuracy / len(val_loader)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(model_dir, \"bigger_binary_F1_0.98.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for img, label in data:\n",
    "    res = model(img.reshape((1, 1, 224, 224)).cuda())\n",
    "    y_true.append(label)\n",
    "    y_pred.append(int(res.cpu().detach() >= 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3751    0]\n",
      " [   9  176]]\n",
      "F1:  0.9750692520775623\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)\n",
    "print(\"F1: \", f1_score(y_pred, y_true))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
